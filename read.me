Огляд Проекту
Цей проект реалізує програму для паралельного оброблення та аналізу текстових файлів з метою пошуку заданих ключових слів. Програма має дві версії:

Багатопотоковий підхід з використанням модуля threading.
Багатопроцесорний підхід з використанням модуля multiprocessing.
Метою проекту є порівняння ефективності обох підходів при обробці великих обсягів даних та визначення оптимального методу для різних типів завдань.

Технології
Мова програмування: Python 3
Бібліотеки:
threading
multiprocessing
collections
os
time

Структура Проєкту

parallel_keyword_search/
│
├── 01.py           # Основний скрипт для пошуку ключових слів
├── texts/                      # Директорія з текстовими файлами
├── README.md                   # Документація проекту 

Результати Тестування
Після запуску програми ви побачите результати пошуку ключових слів у двох підходах: багатопотоковому та багатопроцесорному. Також буде виведено час виконання кожного підходу.

Початок пошуку ключових слів у файлах...

Багатопотоковий підхід виконано за 0.00 секунд.

Результати багатопотокового пошуку:
'слово1' знайдено у файлах:
  - texts/file1.txt
  - texts/file3.txt
  - texts/file5.txt
'слово3' знайдено у файлах:
  - texts/file1.txt
  - texts/file5.txt
'слово2' знайдено у файлах:
  - texts/file5.txt

--------------------------------------------------

Багатопроцесорний підхід виконано за 0.13 секунд.

Результати багатопроцесорного пошуку:
'слово1' знайдено у файлах:
  - texts/file3.txt
  - texts/file5.txt
  - texts/file1.txt
'слово2' знайдено у файлах:
  - texts/file5.txt
'слово3' знайдено у файлах:
  - texts/file5.txt
  - texts/file1.txt

--------------------------------------------------

Час виконання багатопотокового підходу: 0.00 секунд.
Час виконання багатопроцесорного підходу: 0.13 секунд.